{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9IKCTdp39fW"
   },
   "source": [
    "# Machine Learning Trading Bot\n",
    "\n",
    "## Background\n",
    "- Three machine learning models were utilized to train and predict the trading data sourced from Alpaca API. \n",
    "- The target was determined to be the entry price plus 3 times the Average True Range(ATR): '1'.\n",
    "- The stop was determined to be the entry price minus the Average True Range (ATR): '-1'. \n",
    "- Support Vector Machine (SVM), Decision Tree models, and Stochasstic Gradient Descent (SGD) were applied to this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l9IKCTdp39fW"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.2/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.2/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.2.2/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.2/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.2/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.2/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.2.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# initial imports\n",
    "from pathlib import Path \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from finta import TA\n",
    "\n",
    "import pandas as pd \n",
    "import hvplot.pandas\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-19 13:20:00+00:00</th>\n",
       "      <td>1645.9000</td>\n",
       "      <td>1646.1435</td>\n",
       "      <td>1644.6375</td>\n",
       "      <td>1644.7265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 13:25:00+00:00</th>\n",
       "      <td>1644.6865</td>\n",
       "      <td>1645.8945</td>\n",
       "      <td>1644.3040</td>\n",
       "      <td>1644.9655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 13:30:00+00:00</th>\n",
       "      <td>1644.8480</td>\n",
       "      <td>1644.8480</td>\n",
       "      <td>1644.5800</td>\n",
       "      <td>1644.7550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 13:35:00+00:00</th>\n",
       "      <td>1645.5160</td>\n",
       "      <td>1647.5000</td>\n",
       "      <td>1645.5160</td>\n",
       "      <td>1647.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 13:40:00+00:00</th>\n",
       "      <td>1648.0300</td>\n",
       "      <td>1648.0300</td>\n",
       "      <td>1646.0030</td>\n",
       "      <td>1646.2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 17:55:00+00:00</th>\n",
       "      <td>1629.8650</td>\n",
       "      <td>1631.0300</td>\n",
       "      <td>1629.0965</td>\n",
       "      <td>1629.0965</td>\n",
       "      <td>0.032812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1631.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:00:00+00:00</th>\n",
       "      <td>1629.1000</td>\n",
       "      <td>1631.7700</td>\n",
       "      <td>1626.0550</td>\n",
       "      <td>1628.8060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:05:00+00:00</th>\n",
       "      <td>1628.4800</td>\n",
       "      <td>1631.0210</td>\n",
       "      <td>1628.4600</td>\n",
       "      <td>1630.0180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:10:00+00:00</th>\n",
       "      <td>1629.5380</td>\n",
       "      <td>1630.9575</td>\n",
       "      <td>1628.9500</td>\n",
       "      <td>1630.7255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:15:00+00:00</th>\n",
       "      <td>1630.2100</td>\n",
       "      <td>1634.9675</td>\n",
       "      <td>1630.2100</td>\n",
       "      <td>1634.3670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                open       high        low      close  \\\n",
       "timestamp                                                               \n",
       "2023-09-19 13:20:00+00:00  1645.9000  1646.1435  1644.6375  1644.7265   \n",
       "2023-09-19 13:25:00+00:00  1644.6865  1645.8945  1644.3040  1644.9655   \n",
       "2023-09-19 13:30:00+00:00  1644.8480  1644.8480  1644.5800  1644.7550   \n",
       "2023-09-19 13:35:00+00:00  1645.5160  1647.5000  1645.5160  1647.5000   \n",
       "2023-09-19 13:40:00+00:00  1648.0300  1648.0300  1646.0030  1646.2500   \n",
       "...                              ...        ...        ...        ...   \n",
       "2023-09-20 17:55:00+00:00  1629.8650  1631.0300  1629.0965  1629.0965   \n",
       "2023-09-20 18:00:00+00:00  1629.1000  1631.7700  1626.0550  1628.8060   \n",
       "2023-09-20 18:05:00+00:00  1628.4800  1631.0210  1628.4600  1630.0180   \n",
       "2023-09-20 18:10:00+00:00  1629.5380  1630.9575  1628.9500  1630.7255   \n",
       "2023-09-20 18:15:00+00:00  1630.2100  1634.9675  1630.2100  1634.3670   \n",
       "\n",
       "                             volume  trade_count     vwap  \n",
       "timestamp                                                  \n",
       "2023-09-19 13:20:00+00:00  0.000000          0.0     0.00  \n",
       "2023-09-19 13:25:00+00:00  0.000000          0.0     0.00  \n",
       "2023-09-19 13:30:00+00:00  0.000000          0.0     0.00  \n",
       "2023-09-19 13:35:00+00:00  0.000000          0.0     0.00  \n",
       "2023-09-19 13:40:00+00:00  0.000000          0.0     0.00  \n",
       "...                             ...          ...      ...  \n",
       "2023-09-20 17:55:00+00:00  0.032812          1.0  1631.03  \n",
       "2023-09-20 18:00:00+00:00  0.000000          0.0     0.00  \n",
       "2023-09-20 18:05:00+00:00  0.000000          0.0     0.00  \n",
       "2023-09-20 18:10:00+00:00  0.000000          0.0     0.00  \n",
       "2023-09-20 18:15:00+00:00  0.000000          0.0     0.00  \n",
       "\n",
       "[347 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import alpaca\n",
    "from alpaca.data.historical import CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "ticker = \"ETH/USD\"\n",
    "time_diff = datetime.now() - relativedelta(days=1)\n",
    "\n",
    "# Alpaca Market Data Client\n",
    "data_client = CryptoHistoricalDataClient()\n",
    "\n",
    "# Defining Bar data request parameters\n",
    "request_params = CryptoBarsRequest(\n",
    "    symbol_or_symbols=[ticker],\n",
    "    timeframe=TimeFrame(5, alpaca.data.timeframe.TimeFrameUnit.Minute),\n",
    "    start=time_diff\n",
    ")\n",
    "\n",
    "# Get the bar data from Alpaca\n",
    "signals_df = data_client.get_crypto_bars(request_params).df\n",
    "\n",
    "signals_df.reset_index(level='symbol', inplace=True)\n",
    "signals_df.drop(columns=[\"symbol\"], inplace=True)\n",
    "\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save copy\n",
    "# signals_df.to_csv(\"./ETH_time_series.csv\", index=\"timestamp\")\n",
    "\n",
    "# signals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download stock time-series data from Alpaca API into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-20 08:00:00+00:00</th>\n",
       "      <td>442.98</td>\n",
       "      <td>442.98</td>\n",
       "      <td>442.7200</td>\n",
       "      <td>442.7200</td>\n",
       "      <td>2024</td>\n",
       "      <td>28</td>\n",
       "      <td>442.885479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 08:05:00+00:00</th>\n",
       "      <td>442.65</td>\n",
       "      <td>442.78</td>\n",
       "      <td>442.6500</td>\n",
       "      <td>442.7800</td>\n",
       "      <td>1146</td>\n",
       "      <td>20</td>\n",
       "      <td>442.725855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 08:10:00+00:00</th>\n",
       "      <td>442.76</td>\n",
       "      <td>442.88</td>\n",
       "      <td>442.7100</td>\n",
       "      <td>442.7100</td>\n",
       "      <td>1169</td>\n",
       "      <td>17</td>\n",
       "      <td>442.787690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 08:15:00+00:00</th>\n",
       "      <td>442.77</td>\n",
       "      <td>442.99</td>\n",
       "      <td>442.7600</td>\n",
       "      <td>442.9900</td>\n",
       "      <td>6397</td>\n",
       "      <td>37</td>\n",
       "      <td>442.934617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 08:20:00+00:00</th>\n",
       "      <td>443.05</td>\n",
       "      <td>443.25</td>\n",
       "      <td>443.0500</td>\n",
       "      <td>443.2500</td>\n",
       "      <td>6324</td>\n",
       "      <td>47</td>\n",
       "      <td>443.200768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 17:40:00+00:00</th>\n",
       "      <td>443.25</td>\n",
       "      <td>443.25</td>\n",
       "      <td>443.0700</td>\n",
       "      <td>443.2000</td>\n",
       "      <td>486428</td>\n",
       "      <td>3944</td>\n",
       "      <td>443.212220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 17:45:00+00:00</th>\n",
       "      <td>443.20</td>\n",
       "      <td>443.23</td>\n",
       "      <td>443.0900</td>\n",
       "      <td>443.2000</td>\n",
       "      <td>519492</td>\n",
       "      <td>2269</td>\n",
       "      <td>442.996283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 17:50:00+00:00</th>\n",
       "      <td>443.20</td>\n",
       "      <td>443.64</td>\n",
       "      <td>443.1500</td>\n",
       "      <td>443.6195</td>\n",
       "      <td>302994</td>\n",
       "      <td>3034</td>\n",
       "      <td>443.374751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 17:55:00+00:00</th>\n",
       "      <td>443.62</td>\n",
       "      <td>443.71</td>\n",
       "      <td>443.5200</td>\n",
       "      <td>443.5750</td>\n",
       "      <td>378037</td>\n",
       "      <td>3085</td>\n",
       "      <td>443.602338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:00:00+00:00</th>\n",
       "      <td>443.59</td>\n",
       "      <td>443.59</td>\n",
       "      <td>441.5419</td>\n",
       "      <td>442.1400</td>\n",
       "      <td>3268355</td>\n",
       "      <td>22520</td>\n",
       "      <td>442.189294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             open    high       low     close   volume  \\\n",
       "timestamp                                                                \n",
       "2023-09-20 08:00:00+00:00  442.98  442.98  442.7200  442.7200     2024   \n",
       "2023-09-20 08:05:00+00:00  442.65  442.78  442.6500  442.7800     1146   \n",
       "2023-09-20 08:10:00+00:00  442.76  442.88  442.7100  442.7100     1169   \n",
       "2023-09-20 08:15:00+00:00  442.77  442.99  442.7600  442.9900     6397   \n",
       "2023-09-20 08:20:00+00:00  443.05  443.25  443.0500  443.2500     6324   \n",
       "...                           ...     ...       ...       ...      ...   \n",
       "2023-09-20 17:40:00+00:00  443.25  443.25  443.0700  443.2000   486428   \n",
       "2023-09-20 17:45:00+00:00  443.20  443.23  443.0900  443.2000   519492   \n",
       "2023-09-20 17:50:00+00:00  443.20  443.64  443.1500  443.6195   302994   \n",
       "2023-09-20 17:55:00+00:00  443.62  443.71  443.5200  443.5750   378037   \n",
       "2023-09-20 18:00:00+00:00  443.59  443.59  441.5419  442.1400  3268355   \n",
       "\n",
       "                           trade_count        vwap  \n",
       "timestamp                                           \n",
       "2023-09-20 08:00:00+00:00           28  442.885479  \n",
       "2023-09-20 08:05:00+00:00           20  442.725855  \n",
       "2023-09-20 08:10:00+00:00           17  442.787690  \n",
       "2023-09-20 08:15:00+00:00           37  442.934617  \n",
       "2023-09-20 08:20:00+00:00           47  443.200768  \n",
       "...                                ...         ...  \n",
       "2023-09-20 17:40:00+00:00         3944  443.212220  \n",
       "2023-09-20 17:45:00+00:00         2269  442.996283  \n",
       "2023-09-20 17:50:00+00:00         3034  443.374751  \n",
       "2023-09-20 17:55:00+00:00         3085  443.602338  \n",
       "2023-09-20 18:00:00+00:00        22520  442.189294  \n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THE FOLLOWING IS TO REQUEST IN DATA USING THE ALPACA_API\n",
    "# API credentials\n",
    "API_KEY = 'PKD98H4EZF8YRDLUZ5I2'\n",
    "SECRET_KEY = 'b5ZbNnx35m3uaB6vRnrU7TLQlgEfDw0bKf1Y8Zsm'\n",
    "API_BASE_URL = \"https://paper-api.alpaca.markets\"\n",
    "\n",
    "# Create a connection to the API \n",
    "api = tradeapi.REST(API_KEY, SECRET_KEY, API_BASE_URL, api_version=\"v2\")\n",
    "    \n",
    "# Set the ticket symbol and the number of shares to buy\n",
    "ticker = \"SPY\"\n",
    "\n",
    "# Make API call\n",
    "signals_df = api.get_bars(ticker, \"5min\", start=\"2023-09-20\").df\n",
    "\n",
    "# # Save the DataFrame with the date index\n",
    "# signals_df.to_csv('SPY_15min_time_series_df.csv')\n",
    "\n",
    "# create a seperate dataframe for signals\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">SPY</th>\n",
       "      <th>2023-09-19 14:30:00+00:00</th>\n",
       "      <td>441.625</td>\n",
       "      <td>441.625</td>\n",
       "      <td>440.540</td>\n",
       "      <td>440.8900</td>\n",
       "      <td>2340711.0</td>\n",
       "      <td>23453.0</td>\n",
       "      <td>441.008786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 14:45:00+00:00</th>\n",
       "      <td>440.870</td>\n",
       "      <td>441.120</td>\n",
       "      <td>440.510</td>\n",
       "      <td>440.5800</td>\n",
       "      <td>2104764.0</td>\n",
       "      <td>17842.0</td>\n",
       "      <td>440.747120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 15:00:00+00:00</th>\n",
       "      <td>440.580</td>\n",
       "      <td>440.920</td>\n",
       "      <td>440.495</td>\n",
       "      <td>440.8900</td>\n",
       "      <td>2375383.0</td>\n",
       "      <td>15406.0</td>\n",
       "      <td>440.676297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 15:15:00+00:00</th>\n",
       "      <td>440.880</td>\n",
       "      <td>440.890</td>\n",
       "      <td>440.510</td>\n",
       "      <td>440.8900</td>\n",
       "      <td>1457359.0</td>\n",
       "      <td>12175.0</td>\n",
       "      <td>440.684586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19 15:30:00+00:00</th>\n",
       "      <td>440.865</td>\n",
       "      <td>441.040</td>\n",
       "      <td>440.630</td>\n",
       "      <td>440.6791</td>\n",
       "      <td>1778444.0</td>\n",
       "      <td>11571.0</td>\n",
       "      <td>440.832287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:00:00+00:00</th>\n",
       "      <td>443.590</td>\n",
       "      <td>443.590</td>\n",
       "      <td>441.530</td>\n",
       "      <td>442.1900</td>\n",
       "      <td>5922272.0</td>\n",
       "      <td>43099.0</td>\n",
       "      <td>442.147391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:15:00+00:00</th>\n",
       "      <td>442.180</td>\n",
       "      <td>442.950</td>\n",
       "      <td>442.030</td>\n",
       "      <td>442.6000</td>\n",
       "      <td>2282202.0</td>\n",
       "      <td>18494.0</td>\n",
       "      <td>442.478799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:30:00+00:00</th>\n",
       "      <td>442.570</td>\n",
       "      <td>443.750</td>\n",
       "      <td>442.220</td>\n",
       "      <td>442.9800</td>\n",
       "      <td>4127891.0</td>\n",
       "      <td>31994.0</td>\n",
       "      <td>443.146052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 18:45:00+00:00</th>\n",
       "      <td>443.010</td>\n",
       "      <td>443.160</td>\n",
       "      <td>441.470</td>\n",
       "      <td>441.8100</td>\n",
       "      <td>4237706.0</td>\n",
       "      <td>32353.0</td>\n",
       "      <td>442.097769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20 19:00:00+00:00</th>\n",
       "      <td>441.800</td>\n",
       "      <td>442.260</td>\n",
       "      <td>440.600</td>\n",
       "      <td>440.6800</td>\n",
       "      <td>3304231.0</td>\n",
       "      <td>27690.0</td>\n",
       "      <td>441.498994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     open     high      low     close  \\\n",
       "symbol timestamp                                                        \n",
       "SPY    2023-09-19 14:30:00+00:00  441.625  441.625  440.540  440.8900   \n",
       "       2023-09-19 14:45:00+00:00  440.870  441.120  440.510  440.5800   \n",
       "       2023-09-19 15:00:00+00:00  440.580  440.920  440.495  440.8900   \n",
       "       2023-09-19 15:15:00+00:00  440.880  440.890  440.510  440.8900   \n",
       "       2023-09-19 15:30:00+00:00  440.865  441.040  440.630  440.6791   \n",
       "...                                   ...      ...      ...       ...   \n",
       "       2023-09-20 18:00:00+00:00  443.590  443.590  441.530  442.1900   \n",
       "       2023-09-20 18:15:00+00:00  442.180  442.950  442.030  442.6000   \n",
       "       2023-09-20 18:30:00+00:00  442.570  443.750  442.220  442.9800   \n",
       "       2023-09-20 18:45:00+00:00  443.010  443.160  441.470  441.8100   \n",
       "       2023-09-20 19:00:00+00:00  441.800  442.260  440.600  440.6800   \n",
       "\n",
       "                                     volume  trade_count        vwap  \n",
       "symbol timestamp                                                      \n",
       "SPY    2023-09-19 14:30:00+00:00  2340711.0      23453.0  441.008786  \n",
       "       2023-09-19 14:45:00+00:00  2104764.0      17842.0  440.747120  \n",
       "       2023-09-19 15:00:00+00:00  2375383.0      15406.0  440.676297  \n",
       "       2023-09-19 15:15:00+00:00  1457359.0      12175.0  440.684586  \n",
       "       2023-09-19 15:30:00+00:00  1778444.0      11571.0  440.832287  \n",
       "...                                     ...          ...         ...  \n",
       "       2023-09-20 18:00:00+00:00  5922272.0      43099.0  442.147391  \n",
       "       2023-09-20 18:15:00+00:00  2282202.0      18494.0  442.478799  \n",
       "       2023-09-20 18:30:00+00:00  4127891.0      31994.0  443.146052  \n",
       "       2023-09-20 18:45:00+00:00  4237706.0      32353.0  442.097769  \n",
       "       2023-09-20 19:00:00+00:00  3304231.0      27690.0  441.498994  \n",
       "\n",
       "[83 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_data.py\n",
    "\n",
    "import alpaca\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "APCA_API_KEY_ID = 'PKD98H4EZF8YRDLUZ5I2'\n",
    "APCA_API_SECRET_KEY = 'b5ZbNnx35m3uaB6vRnrU7TLQlgEfDw0bKf1Y8Zsm'\n",
    "ticker = \"SPY\"\n",
    "timeDiff = datetime.now() - relativedelta(days=1)\n",
    "# keys required for stock historical data client\n",
    "client = StockHistoricalDataClient(APCA_API_KEY_ID, APCA_API_SECRET_KEY)\n",
    "\n",
    "# multi symbol request - single symbol is similar\n",
    "multisymbol_request_params = StockBarsRequest(\n",
    "    symbol_or_symbols=[ticker],\n",
    "    timeframe=TimeFrame(15, alpaca.data.timeframe.TimeFrameUnit.Minute),\n",
    "    start=timeDiff)\n",
    "\n",
    "latest_multisymbol_quotes = client.get_stock_bars(multisymbol_request_params).df\n",
    "latest_multisymbol_quotes\n",
    "\n",
    "# signals_df.drop(columns=[\"symbol\"], inplace=True)\n",
    "\n",
    "# signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPY': {   'close': 442.43,\n",
       "     'high': 442.44,\n",
       "     'low': 442.24,\n",
       "     'open': 442.24,\n",
       "     'symbol': 'SPY',\n",
       "     'timestamp': datetime.datetime(2023, 9, 20, 18, 22, tzinfo=datetime.timezone.utc),\n",
       "     'trade_count': 14.0,\n",
       "     'volume': 1024.0,\n",
       "     'vwap': 442.337046}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_data.py\n",
    "\n",
    "import alpaca\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockLatestBarRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "APCA_API_KEY_ID = 'PKD98H4EZF8YRDLUZ5I2'\n",
    "APCA_API_SECRET_KEY = 'b5ZbNnx35m3uaB6vRnrU7TLQlgEfDw0bKf1Y8Zsm'\n",
    "ticker = \"SPY\"\n",
    "timeDiff = datetime.now() - relativedelta(days=1)\n",
    "# keys required for stock historical data client\n",
    "client = StockHistoricalDataClient(APCA_API_KEY_ID, APCA_API_SECRET_KEY)\n",
    "\n",
    "# multi symbol request - single symbol is similar\n",
    "multisymbol_request_params = StockLatestBarRequest(\n",
    "    symbol_or_symbols=[ticker],\n",
    "    timeframe=TimeFrame(5, alpaca.data.timeframe.TimeFrameUnit.Minute),\n",
    "    start=timeDiff)\n",
    "\n",
    "latest_multisymbol_quotes = client.get_stock_latest_bar(multisymbol_request_params)\n",
    "latest_multisymbol_quotes\n",
    "\n",
    "# signals_df.drop(columns=[\"symbol\"], inplace=True)\n",
    "\n",
    "# signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mStockBarsRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msymbol_or_symbols\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcurrency\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malpaca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSupportedCurrencies\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtimeframe\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0malpaca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeFrame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0madjustment\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malpaca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdjustment\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfeed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malpaca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFeed\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "The request model for retrieving bar data for equities.\n",
       "\n",
       "See BaseGetBarsRequest for more information on available parameters.\n",
       "\n",
       "Attributes:\n",
       "    symbol_or_symbols (Union[str, List[str]]): The ticker identifier or list of ticker identifiers.\n",
       "    start (Optional[datetime]): The beginning of the time interval for desired data. Timezone naive inputs assumed to be in UTC.\n",
       "    end (Optional[datetime]): The end of the time interval for desired data. Defaults to now. Timezone naive inputs assumed to be in UTC.\n",
       "    limit (Optional[int]): Upper limit of number of data points to return. Defaults to None.\n",
       "    adjustment (Optional[Adjustment]): The type of corporate action data normalization.\n",
       "    feed (Optional[DataFeed]): The stock data feed to retrieve from.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Create a new model by parsing and validating input data from keyword arguments.\n",
       "\n",
       "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\range\\anaconda3\\envs\\turboalgobotlab\\lib\\site-packages\\alpaca\\data\\requests.py\n",
       "\u001b[1;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "StockBarsRequest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_bars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(signals_df.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read in stock time-series data from .csv file into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set ticker\n",
    "# ticker = \"AAPL\"\n",
    "\n",
    "# # Load the DataFrame from a CSV file\n",
    "# signals_df = pd.read_csv('AAPL_time_series_df.csv', index_col=\"timestamp\")\n",
    "\n",
    "# # Convert the first column (assuming it contains datetime-like values) to DatetimeIndex\n",
    "# signals_df.index = pd.to_datetime(signals_df.index)\n",
    "\n",
    "# # Define NYSE regular trading hours\n",
    "# nyse_opening_time = pd.Timestamp(\"09:30:00\")\n",
    "# nyse_closing_time = pd.Timestamp(\"16:00:00\")\n",
    "\n",
    "# # Filter the DataFrame to include only data within NYSE regular trading hours\n",
    "# signals_df = signals_df.between_time(nyse_opening_time.time(), nyse_closing_time.time())\n",
    "\n",
    "# # save copy\n",
    "# signals_df.to_csv(\"../data/SPY_time_series.csv\", index=\"timestamp\")\n",
    "\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot closing prices\n",
    "signals_df['close'].plot(title=f'{ticker} Closing Prices', xlabel=\"Timestamp\", ylabel='Closing Price')\n",
    "# plt.savefig(f'{ticker}_closing_prices', facecolor='white', edgecolor='white', transparent='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Features (Techincal Analysis Indicators) to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous features (techinal indicators) may be used\n",
    "features = [\"open\", \"high\", \"low\", \"close\", \"volume\", \"trade_count\", \"vwap\", \"9EMA\", \"20EMA\", \"50EMA\", \"200SMA\", \"ATR\", \"RSI\", \"BB_UPPER\", \"BB_MIDDLE\", \"BB_LOWER\", \"MACD\"]\n",
    "\n",
    "#  Setup EMAs for crosses\n",
    "longest_MA_window = 200\n",
    "signals_df[\"9EMA\"] = TA.EMA(signals_df, 9)\n",
    "signals_df[\"20EMA\"] = TA.EMA(signals_df, 20)\n",
    "signals_df[\"50EMA\"] = TA.EMA(signals_df, 50)\n",
    "signals_df[\"200SMA\"] = TA.SMA(signals_df, longest_MA_window)\n",
    "\n",
    "# Setup Indicators\n",
    "signals_df[\"ATR\"] = TA.ATR(signals_df)\n",
    "bbands_df = TA.BBANDS(signals_df)\n",
    "macd_df = TA.MACD(signals_df)\n",
    "signals_df[\"RSI\"] = TA.RSI(signals_df)\n",
    "\n",
    "# join macd and bbands Dataframes to signals_df\n",
    "bbands_df = pd.concat([bbands_df, macd_df], axis=1)\n",
    "signals_df = pd.concat([signals_df, bbands_df], axis=1)\n",
    "signals_df.drop(columns=[\"SIGNAL\"], inplace=True)\n",
    "\n",
    "# Exit is the labeled target for ML, Exit Price is for use in Pnl Metrics\n",
    "signals_df[\"Entry Price\"] = 0\n",
    "signals_df[\"Entry Time\"] = 0\n",
    "\n",
    "signals_df[\"Exit Price\"] = 0\n",
    "signals_df[\"Exit Time\"] = 0\n",
    "signals_df[\"Exit\"] = 0\n",
    "\n",
    "# Review DataFrame\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NYSE regular trading hours\n",
    "nyse_opening_time = pd.Timestamp(\"09:30:00\")\n",
    "nyse_closing_time = pd.Timestamp(\"16:00:00\")\n",
    "\n",
    "# Filter the DataFrame to include only data within NYSE regular trading hours\n",
    "signals_df = signals_df.between_time(nyse_opening_time.time(), nyse_closing_time.time())\n",
    "\n",
    "# Review DataFrame\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable the warning\n",
    "pd.options.mode.chained_assignment = None  # \"None\" suppresses the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Volatility Based Targets and Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create the exit column, our \"y\", for use in supervised ML\n",
    "# How many rows are in the signals_df? for use in modifying DataFrame\n",
    "num_rows_in_df = signals_df.shape[0]\n",
    "\n",
    "# reward:risk ratio\n",
    "reward = 6\n",
    "risk = 2\n",
    "\n",
    "# we also figure out our exit price\n",
    "# hitting target price before the stop price signals a win and will be 1\n",
    "# hitting stop price before hitting the target price signals a loss and will be -1\n",
    "# loop thru the dataframe, from the longest_MA_window to the end (num_rows_in_df) to avoid NaN values\n",
    "for j in range(longest_MA_window, num_rows_in_df):\n",
    "    # entries will be on candle close\n",
    "    entry = signals_df[\"close\"].iloc[j]\n",
    "    signals_df[\"Entry Price\"].iloc[j] = entry\n",
    "    signals_df[\"Entry Time\"].iloc[j] = signals_df.index[j]\n",
    "    # calculate volatility for each candle\n",
    "    atr = signals_df[\"ATR\"].iloc[j]\n",
    "    # stop is entry price minus the average volatility for the entry period\n",
    "    stop = entry - (risk * atr)\n",
    "    # target is entry price plus the average volatility for the entry period times a multiplier\n",
    "    target = entry + (reward * atr)\n",
    "    # loop again thru the dataset to compare j entry price to future closing prices to see if we hit target or stop\n",
    "    for k in range(j + 1, num_rows_in_df):\n",
    "        # current low of the candle\n",
    "        curr_low = signals_df[\"low\"].iloc[k]\n",
    "        # current high of the candle\n",
    "        curr_high = signals_df[\"high\"].iloc[k]\n",
    "        # record and break if we hit stop or target, if not we check the next k period\n",
    "        # if current low breaks our stop we should've sold: -1 in our \"Exit\" column\n",
    "        if curr_low <= stop:\n",
    "            signals_df[\"Exit Price\"].iloc[j] = stop\n",
    "            signals_df[\"Exit\"].iloc[j] = -1\n",
    "            # record exit time\n",
    "            signals_df[\"Exit Time\"].iloc[j] = signals_df.index[k] \n",
    "            # if we hit the stop break the inner loop to check the next row\n",
    "            break\n",
    "        # if current high breaks our target we should've sold: +1 in our \"Exit\" column\n",
    "        elif curr_high >= target:\n",
    "            signals_df[\"Exit Price\"].iloc[j] = target\n",
    "            signals_df[\"Exit\"].iloc[j] = 1\n",
    "            # record exit time\n",
    "            signals_df[\"Exit Time\"].iloc[j] = signals_df.index[k] \n",
    "            # if we hit the target break the inner loop to check the next row\n",
    "            break\n",
    "\n",
    "# drop beginning columns to avoid NaN values from EMA/SMA calculations\n",
    "signals_df = signals_df[longest_MA_window:]\n",
    "\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include only rows with an exit time\n",
    "signals_df = signals_df.loc[signals_df[\"Exit Time\"] != 0]\n",
    "\n",
    "# remove all unwanted zeros from the exit column\n",
    "signals_df = signals_df.loc[signals_df[\"Exit\"] != 0]\n",
    "\n",
    "# # include only higher than 1 volume\n",
    "# signals_df = signals_df.loc[signals_df[\"volume\"] != 0]\n",
    "\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot closing prices\n",
    "signals_df['close'].plot(title=f'{ticker} Closing Prices', xlabel=\"Timestamp\", ylabel='Closing Price')\n",
    "# plt.savefig(f'{ticker}_closing_prices', facecolor='white', edgecolor='white', transparent='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we have a sufficient training period\n",
    "training_begin = str(signals_df.index.min())\n",
    "training_end = str(signals_df.index.min() + DateOffset(months=2))\n",
    "\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df.to_csv(\"AAPL_time_series.csv\", index_label=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features\n",
    "X = signals_df[features]\n",
    "\n",
    "# 1 means a buy would've produced a profit (hit target/win), -1 means a sale would've produced a profit (his stop/loss)\n",
    "y = signals_df[\"Exit\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train = X.loc[training_begin: training_end]\n",
    "y_train = y.loc[training_begin: training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "undersampled_X_train_scaled, undersampled_y_train = rus.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVC) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier model\n",
    "model = svm.SVC(probability=True, random_state=1)\n",
    " \n",
    "# Fit the model to the data using undersampled_X_train_scaled and undersampled_y_train\n",
    "model = model.fit(undersampled_X_train_scaled, undersampled_y_train)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "training_signal_predictions = model.predict(undersampled_X_train_scaled)\n",
    "training_probability_estimates = model.predict_proba(undersampled_X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'ETH_5MIN_10TO10_SVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the X_Scaler\n",
    "joblib.dump(X_scaler, \"X_scaler.save\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using a classification report\n",
    "training_report = classification_report(undersampled_y_train, training_signal_predictions)\n",
    "print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict the trading signals for the testing data.\n",
    "testing_signal_predictions = model.predict(X_test_scaled)\n",
    "testing_probability_estimates = model.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_test, testing_signal_predictions)\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########CHECK THIS!!!!!!#################\n",
    "# Create a predictions DataFrame for SVM\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "predictions_df[\"predicted_signal\"] = testing_signal_predictions\n",
    "\n",
    "predictions_df[\"actual_returns\"] = signals_df[\"close\"].pct_change()\n",
    "\n",
    "#####################\n",
    "\n",
    "predictions_df[[\"Entry Price\", \"Entry Time\", \"Exit Price\", \"Exit Time\"]] = signals_df[[\"Entry Price\", \"Entry Time\", \"Exit Price\", \"Exit Time\"]]\n",
    "\n",
    "####################\n",
    "\n",
    "predictions_df[\"algo_returns\"] = (signals_df[\"Exit Price\"] - signals_df[\"Entry Price\"])/signals_df[\"Entry Price\"]\n",
    "\n",
    "predictions_df[\"trading_algorithm_returns\"] = predictions_df.pop(\"algo_returns\") * predictions_df[\"predicted_signal\"]\n",
    "\n",
    "predictions_df[\"probability_estimates\"] = testing_probability_estimates[:, 1]\n",
    "\n",
    "predictions_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize buy_signals_df\n",
    "buy_signals_df = pd.DataFrame()\n",
    "buy_signals_df = pd.concat([buy_signals_df, predictions_df.iloc[[0]]])\n",
    "\n",
    "# Loop to execute one buy trade at a time\n",
    "# Initialize the last trade exit time with the first row's exit time\n",
    "last_trade_exit_time = predictions_df[\"Exit Time\"].iloc[0]\n",
    "\n",
    "# Iterate through the DataFrame to find entry points for buy trades\n",
    "for j in range(1, predictions_df.shape[0]):\n",
    "    # Get the entry time and exit signal for the current row\n",
    "    entry_time = predictions_df[\"Entry Time\"].iloc[j]\n",
    "    exit_signal = predictions_df[\"predicted_signal\"].iloc[j]\n",
    "    # Check if the current entry time is before or equal to the last trade's exit time\n",
    "    # or if the exit signal is -1; if so, skip this iteration\n",
    "    if entry_time <= last_trade_exit_time or exit_signal == -1:\n",
    "        continue\n",
    "    else:\n",
    "        # Concatenate the current row to the buy_signals_df DataFrame\n",
    "        buy_signals_df = pd.concat([buy_signals_df, predictions_df.iloc[[j]]])\n",
    "        # Update the last trade exit time with the current row's exit time\n",
    "        last_trade_exit_time = predictions_df[\"Exit Time\"].iloc[j]\n",
    "\n",
    "# # Filter rows where the predicted signal is 1 and the probability estimate is >= prob\n",
    "buy_signals_df = buy_signals_df[(buy_signals_df[\"probability_estimates\"] >= 0.50)]\n",
    "\n",
    "buy_signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_signals_df.to_csv(\"AAPL_signals_df.csv\", index_label=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time period for which you want to calculate the frequency (e.g., in days)\n",
    "start_date = buy_signals_df.index.min()\n",
    "end_date = buy_signals_df.index.max()\n",
    "time_period_days = (end_date - start_date).days + 1  # Adding 1 to include both start and end dates\n",
    "\n",
    "# Filter the winning, losing, and total trades\n",
    "winning_trades = buy_signals_df[buy_signals_df['trading_algorithm_returns'] > 0]\n",
    "losing_trades = buy_signals_df[buy_signals_df['trading_algorithm_returns'] < 0]\n",
    "total_trades = buy_signals_df[\"trading_algorithm_returns\"]\n",
    "\n",
    "# Calculate gross profit (positive returns) and gross loss (negative returns)\n",
    "gross_profit = buy_signals_df[buy_signals_df['trading_algorithm_returns'] > 0]['trading_algorithm_returns'].sum() * 100\n",
    "gross_loss = buy_signals_df[buy_signals_df['trading_algorithm_returns'] < 0]['trading_algorithm_returns'].sum() * 100\n",
    "\n",
    "# Calculate the average return of your trading strategy\n",
    "average_return = buy_signals_df['trading_algorithm_returns'].mean()\n",
    "\n",
    "# Calculate the risk-free rate (e.g., Treasury bill rate)\n",
    "# You need to specify an appropriate risk-free rate for your analysis\n",
    "risk_free_rate = 0.02  # Replace with the risk-free rate you want to use (e.g., 2% for a Treasury bill)\n",
    "\n",
    "# Calculate downside returns (negative returns)\n",
    "downside_returns = buy_signals_df['trading_algorithm_returns'][buy_signals_df['trading_algorithm_returns'] < 0]\n",
    "\n",
    "# Calculate the downside deviation (standard deviation of negative returns)\n",
    "downside_deviation = (downside_returns * 100).std()\n",
    "\n",
    "# Calculate the Risk:Reward Ratio\n",
    "risk_reward_ratio= reward/risk\n",
    "\n",
    "# Calculate the win rate (if you haven't already)\n",
    "win_rate = len(winning_trades) / len(total_trades)\n",
    "\n",
    "# Calculate the profit factor\n",
    "profit_factor = abs(gross_profit / gross_loss)\n",
    "\n",
    "# Calculate the Sortino Ratio\n",
    "sortino_ratio = (average_return - risk_free_rate) / downside_deviation\n",
    "\n",
    "# Calculate the average profit per winning trade\n",
    "average_profit_per_winning_trade = winning_trades['trading_algorithm_returns'].mean()\n",
    "\n",
    "# Calculate the average loss per losing trade\n",
    "average_loss_per_losing_trade = losing_trades['trading_algorithm_returns'].mean()\n",
    "\n",
    "# Calculate the trade frequency (trades per day)\n",
    "trade_frequency_per_day = len(total_trades) / time_period_days\n",
    "\n",
    "# Calculate the volatility of your trading strategy's returns\n",
    "algo_volatility = buy_signals_df['trading_algorithm_returns'].std()\n",
    "\n",
    "# Calculate the cumulative returns of the algo\n",
    "cumulative_returns = ( 1 + buy_signals_df['trading_algorithm_returns']).sum()\n",
    "\n",
    "# Print the sorted metrics by importance\n",
    "print(\"Risk:Reward Ratio:\", risk_reward_ratio)\n",
    "print(\"Win Rate (%):\", win_rate * 100)\n",
    "print(\"Profit Factor:\", profit_factor)\n",
    "print(\"Sortino Ratio:\", sortino_ratio)\n",
    "print(\"Average Profit per Winning Trade (%):\", average_profit_per_winning_trade * 100)\n",
    "print(\"Average Loss per Losing Trade (%):\", average_loss_per_losing_trade * 100)\n",
    "print(\"Average Return (%):\", average_return * 100)\n",
    "print(\"Trade Frequency (Trades per Day):\", trade_frequency_per_day)\n",
    "print(\"Downside Deviation:\", downside_deviation)\n",
    "print(\"Volatility (Standard Deviation of Algo Returns):\", algo_volatility)\n",
    "print(\"Gross Profit (%):\", gross_profit)\n",
    "print(\"Gross Loss (%):\", gross_loss)\n",
    "print(\"Total Number of Winning Trades:\", len(winning_trades))\n",
    "print(\"Total Number of Trades:\", len(total_trades))\n",
    "print(\"Risk-Free Rate (%):\", risk_free_rate * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### WIP METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum drawdown (MDD)\n",
    "# peters ratio\n",
    "# t-stat\n",
    "# kelly criterion\n",
    "# sharpe ratio\n",
    "# calmar ratio\n",
    "# pain/gain ratio\n",
    "# ulcer index\n",
    "# k-ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate cumulative returns for the algorithmic trading strategy\n",
    "buy_signals_df.loc[:, \"Cumulative Algo Returns\"] = (1 + buy_signals_df.loc[:, \"trading_algorithm_returns\"]).cumprod()\n",
    "\n",
    "# Calculate cumulative returns for the actual stock returns\n",
    "predictions_df.loc[:, \"Cumulative Actual Returns\"] = (1 + predictions_df.loc[:, \"actual_returns\"]).cumprod()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(buy_signals_df.index, buy_signals_df[\"Cumulative Algo Returns\"], label=\"Algorithm Returns (Buy Signals)\")\n",
    "plt.plot(predictions_df.index, predictions_df[\"Cumulative Actual Returns\"], label=\"Actual Returns\")\n",
    "plt.xlabel(\"Date\") \n",
    "plt.ylabel(\"Cumulative Returns\")\n",
    "plt.title(\"Cumulative Returns of Algorithm vs. Actual Returns\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataframe is named 'buy_signals_df'\n",
    "# Step 2: Calculate cumulative returns\n",
    "buy_signals_df['cumulative_returns'] = (1 + buy_signals_df['trading_algorithm_returns']).cumprod()\n",
    "\n",
    "# Step 3: Calculate the peak\n",
    "buy_signals_df['peak'] = buy_signals_df['cumulative_returns'].cummax()\n",
    "\n",
    "# Step 4: Calculate drawdown\n",
    "buy_signals_df['drawdown'] = buy_signals_df['cumulative_returns'] / buy_signals_df['peak'] - 1\n",
    "\n",
    "# Step 5: Find the maximum drawdown\n",
    "max_drawdown = buy_signals_df['drawdown'].min()\n",
    "\n",
    "print(\"Maximum Drawdown (MDD): {:.2%}\".format(max_drawdown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Create a Figure with a Surface plot using the provided DataFrame\n",
    "fig2 = go.Figure(data=[go.Surface(z=metrics_df.values)])\n",
    "\n",
    "# Update the traces for contour lines\n",
    "fig2.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
    "                                  highlightcolor=\"limegreen\", project_z=True))\n",
    "\n",
    "# # Update the layout\n",
    "# fig.update_layout(title='3D Contour Plot', autosize=False,\n",
    "#                   scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
    "#                   width=500, height=500,\n",
    "#                   margin=dict(l=65, r=50, b=65, t=90)\n",
    "# )\n",
    "\n",
    "# Show the plot\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
